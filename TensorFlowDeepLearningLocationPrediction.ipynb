{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e58f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef7332",
   "metadata": {},
   "source": [
    "## Show files in the project dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectDir='C:/work/projects/position-data-generator'\n",
    "fl = os.listdir(projectDir)\n",
    "print(fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a373d",
   "metadata": {},
   "source": [
    "## Show one of the files - daily EU trajectory example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ef416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming the files are in the notebook's directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "files = [f for f in os.listdir(projectDir) if re.match(r'day_[0-9]+_UE3_output\\.csv', f)]\n",
    "\n",
    "def date_chars(s):\n",
    "    start = s.find(\"day_\") + len(\"day_\")\n",
    "    end   = s.find(\"_UE\")\n",
    "    substring = s[start:end]\n",
    "    return(int(substring))\n",
    "\n",
    "#sort files by day\n",
    "files = sorted(files, key = date_chars) \n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(projectDir+\"/\"+file)\n",
    "    x = df.x \n",
    "    y = df.y  \n",
    "    \n",
    "    plt.scatter(x, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce779a8",
   "metadata": {},
   "source": [
    "## create time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b36a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(projectDir) if re.match(r'day_[0-9]+_UE3_output\\.csv', f)]\n",
    "\n",
    "#sort files by day\n",
    "files = sorted(files, key = date_chars) \n",
    "\n",
    "def fillMinutesFromMidnight(firstHour, firstMinute, location, multiplier):\n",
    "    minutesNow = firstHour * 60 + firstMinute\n",
    "    #print(minutesNow)\n",
    "    return pd.Series(location, index=range(0, minutesNow))\n",
    "\n",
    "def fillMinutesTillMidnight(lastHour, lastMinute, location, multiplier):\n",
    "    minutesSpend = (24 * 60) - (lastHour * 60 + lastMinute) - 1\n",
    "    #print(minutesSpend)\n",
    "    return pd.Series(location, index=range(0, minutesSpend))                    \n",
    "\n",
    "def fillTheGap(perCells,currentHour,nextHour,currentMinute,nextMin,currentLocation):\n",
    "    \n",
    "    gap = (nextHour*60+nextMin) - (currentHour*60+currentMinute)\n",
    "    \n",
    "    if gap>1:\n",
    "        for i in range(0, int(gap)-1):\n",
    "            perCells = pd.concat((perCells, pd.Series(currentLocation, dtype='float64')))  \n",
    "    \n",
    "    return perCells\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def fillOutCell(cell, hour, minute, multiplier):\n",
    "    length      =  minute.size\n",
    "    serCells      = pd.Series(dtype='float64')\n",
    "    serHours      = pd.Series(dtype='float64')\n",
    "    serMinut      = pd.Series(dtype='float64')\n",
    "    firstHour     =  hour.values[0]\n",
    "    firstMinute   =  minute.values[0]\n",
    "    firstLocation =  cell.values[0]\n",
    "    \n",
    "    \n",
    "    currentHour   = firstHour\n",
    "    currentMinute = firstMinute\n",
    "    currentLocation = firstLocation\n",
    "    \n",
    "    serCells = pd.concat((serCells, pd.Series(currentLocation, dtype='float64')))\n",
    "    serHours = pd.concat((serHours, pd.Series(currentHour, dtype='float64')))\n",
    "    serMinut = pd.concat((serMinut, pd.Series(currentMinute, dtype='float64')))\n",
    "    \n",
    "    for i in range(1, length):\n",
    "        if((currentHour != hour.values[i]) | (currentMinute!=minute.values[i])):\n",
    "            currentHour     = hour.values[i]\n",
    "            currentMinute   = minute.values[i]\n",
    "            currentLocation = cell.values[i]\n",
    "            serCells = pd.concat((serCells, pd.Series(currentLocation, dtype='float64')))\n",
    "            serHours = pd.concat((serHours, pd.Series(currentHour, dtype='float64')))\n",
    "            serMinut = pd.concat((serMinut, pd.Series(currentMinute, dtype='float64')))\n",
    "            \n",
    "    \n",
    "    #now times without duplicates, but may have gaps between minutes\n",
    "    length      =  serMinut.size\n",
    "    #for i in range(0, length):\n",
    "    #    print(serHours.values[i], serMinut.values[i])\n",
    "    firstHour     =  serHours.values[0]\n",
    "    firstMinute   =  serMinut.values[0]\n",
    "    firstLocation =  serCells.values[0]\n",
    "    \n",
    "    perCells      = pd.Series(dtype='float64')\n",
    "    \n",
    "    \n",
    "    currentHour   = firstHour\n",
    "    currentMinute = firstMinute\n",
    "    currentLocation = firstLocation\n",
    "    \n",
    "    perCells = pd.concat((perCells, pd.Series(currentLocation, dtype='float64')))  \n",
    "    \n",
    "    for i in range(1, length):\n",
    "        nextHour = serHours.values[i]\n",
    "        nextMin  = serMinut.values[i]\n",
    "        nextLoc  = serCells.values[i]\n",
    "        perCells = fillTheGap(perCells,currentHour,nextHour,currentMinute,nextMin,currentLocation)\n",
    "        currentHour   = nextHour\n",
    "        currentMinute = nextMin\n",
    "        currentLocation = nextLoc    \n",
    "        perCells = pd.concat((perCells, pd.Series(currentLocation, dtype='float64')))      \n",
    "    \n",
    "    return perCells\n",
    "\n",
    "countWrongs = 0\n",
    "\n",
    "series = pd.Series(dtype='float64')\n",
    "\n",
    "MINS_IN_DAY=1440\n",
    "\n",
    "for file in files:\n",
    "    df          =  pd.read_csv(projectDir+\"/\"+file)\n",
    "    cell        =  df.cell\n",
    "    hour        =  df.hour\n",
    "    minute      =  df.minute\n",
    "    length      =  minute.size\n",
    "    firstHour   =  hour.values[0]\n",
    "    lastHour    =  hour.values[length-1]\n",
    "    firstMinute =  minute.values[0]\n",
    "    lastMinute  =  minute.values[length-1]\n",
    "    firstLocation = cell[0]\n",
    "    lastLocation  = cell[length-1]\n",
    "    \n",
    "    \n",
    "    multiplier = 1 # not to go in the resolution smaller than 1 minute\n",
    "    minutesFromMidnight = fillMinutesFromMidnight(firstHour, firstMinute, firstLocation, multiplier)\n",
    "    minutesTillMidnight = fillMinutesTillMidnight(lastHour, lastMinute, lastLocation, multiplier)\n",
    "    cell = fillOutCell(cell, hour, minute,multiplier )#add absent locations in absent times\n",
    "    oneDaySeries = pd.concat((minutesFromMidnight, cell, minutesTillMidnight))\n",
    "    \n",
    "    \n",
    "    size = oneDaySeries.size\n",
    "    if(size!=MINS_IN_DAY):\n",
    "        countWrongs+=1\n",
    "    else:\n",
    "        series = pd.concat((series, oneDaySeries))\n",
    "    \n",
    "    \n",
    "print(countWrongs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efdce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"series size \", series.size)\n",
    "DAYS_COLLECTED=series.size/MINS_IN_DAY\n",
    "print(\"days collected \", DAYS_COLLECTED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e64f6",
   "metadata": {},
   "source": [
    "## plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50420ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_series(x, y, format=\"-\", start=0, end=None, \n",
    "                title=None, xlabel=None, ylabel=None, legend=None ):\n",
    "    \"\"\"\n",
    "    Visualizes time series data\n",
    "\n",
    "    Args:\n",
    "      x (array of int) - contains values for the x-axis\n",
    "      y (array of int or tuple of arrays) - contains the values for the y-axis\n",
    "      format (string) - line style when plotting the graph\n",
    "      start (int) - first time step to plot\n",
    "      end (int) - last time step to plot\n",
    "      title (string) - title of the plot\n",
    "      xlabel (string) - label for the x-axis\n",
    "      ylabel (string) - label for the y-axis\n",
    "      legend (list of strings) - legend for the plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dimensions of the graph figure\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # Check if there are more than two series to plot\n",
    "    if type(y) is tuple:\n",
    "\n",
    "      # Loop over the y elements\n",
    "      for y_curr in y:\n",
    "\n",
    "        # Plot the x and current y values\n",
    "        plt.plot(x[start:end], y_curr[start:end], format)\n",
    "\n",
    "    else:\n",
    "      # Plot the x and y values\n",
    "      plt.plot(x[start:end], y[start:end], format)\n",
    "\n",
    "    # Label the x-axis\n",
    "    plt.xlabel(xlabel)\n",
    "\n",
    "    # Label the y-axis\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    # Set the legend\n",
    "    if legend:\n",
    "      plt.legend(legend)\n",
    "\n",
    "    # Set the title\n",
    "    plt.title(title)\n",
    "\n",
    "    # Overlay a grid on the graph\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Draw the graph on screen\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63a934",
   "metadata": {},
   "source": [
    "## split the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(DAYS_COLLECTED * MINS_IN_DAY , dtype=\"float32\")\n",
    "\n",
    "# Define the split time\n",
    "split_time1 = int(MINS_IN_DAY*DAYS_COLLECTED*0.2)\n",
    "split_time2 = int(MINS_IN_DAY*DAYS_COLLECTED*0.3)\n",
    "print(\"split1 \", split_time1)\n",
    "print(\"split2 \", split_time2)\n",
    "\n",
    "# Get the train set \n",
    "time_train = time[:split_time1]\n",
    "x_train = series[:split_time1]\n",
    "\n",
    "# Get the validation set\n",
    "time_valid = time[split_time1:split_time2]\n",
    "x_valid = series[split_time1:split_time2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361d8ac",
   "metadata": {},
   "source": [
    "## Plot series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429e14a",
   "metadata": {},
   "source": [
    "### Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad60293",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(time[:MINS_IN_DAY], series[:MINS_IN_DAY], xlabel='Time', ylabel='Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90fcf0",
   "metadata": {},
   "source": [
    "### Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68322728",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(time[MINS_IN_DAY:MINS_IN_DAY*2], series[MINS_IN_DAY:MINS_IN_DAY*2], xlabel='Time', ylabel='Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc442a7b",
   "metadata": {},
   "source": [
    "### Day 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b490b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(time[MINS_IN_DAY*199:MINS_IN_DAY*200], series[MINS_IN_DAY*199:MINS_IN_DAY*200], xlabel='Time', ylabel='Value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c40243",
   "metadata": {},
   "source": [
    "### Day 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fe629",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(time[MINS_IN_DAY*299:MINS_IN_DAY*300], series[MINS_IN_DAY*299:MINS_IN_DAY*300], xlabel='Time', ylabel='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "\n",
    "#MINS_TO_WINDOW=MINS_IN_DAY\n",
    "MINS_TO_WINDOW=MINS_IN_DAY\n",
    "window_size = MINS_TO_WINDOW\n",
    "batch_size = 4\n",
    "shuffle_buffer_size = MINS_TO_WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eca31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    \"\"\"Generates dataset windows\n",
    "\n",
    "    Args:\n",
    "      series (array of float) - contains the values of the time series\n",
    "      window_size (int) - the number of time steps to average\n",
    "      batch_size (int) - the batch size\n",
    "      shuffle_buffer(int) - buffer size to use for the shuffle method\n",
    "\n",
    "    Returns:\n",
    "      dataset (TF Dataset) - TF Dataset containing time windows\n",
    "    \"\"\"\n",
    "  \n",
    "    # Generate a TF Dataset from the series values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    \n",
    "    # Window the data but only take those with the specified size\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    \n",
    "    # Flatten the windows by putting its elements in a single batch\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\n",
    "    # Create tuples with features and labels \n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "    # Shuffle the windows\n",
    "    # dataset = dataset.shuffle(shuffle_buffer)\n",
    "    \n",
    "    # Create batches of windows\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d279d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc779abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset states generated by Keras\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(filters=window_size, kernel_size=3,\n",
    "                      strides=1, padding=\"causal\",\n",
    "                      activation=\"relu\",\n",
    "                      input_shape=[window_size, 1]),\n",
    "  tf.keras.layers.LSTM(window_size, return_sequences=True),\n",
    "  tf.keras.layers.LSTM(window_size),\n",
    "  tf.keras.layers.Dense(1),\n",
    "  tf.keras.layers.Lambda(lambda x: x )\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3757ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initial weights\n",
    "init_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea97551",
   "metadata": {},
   "source": [
    "## Create custom Loss for the geometrical x,y coordinates difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAccuracy(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, y_true, y_pred):\n",
    "        \n",
    "        #tf.print(\"y_true\", y_true)\n",
    "        #tf.print(\"y_pred\",y_pred)\n",
    "        \n",
    "        tensSize = tf.size(y_pred)\n",
    "        #tf.print(\"tensSize\",tensSize)\n",
    "        \n",
    "        divider = tf.fill((tensSize,1), 128.0)\n",
    "        #tf.print(\"divider\",divider)\n",
    "        \n",
    "        ytrue=tf.math.divide(y_true,divider)\n",
    "        #tf.print(\"ytrue\", ytrue)\n",
    "        \n",
    "        xtrue=tf.math.subtract(y_true, tf.math.multiply(ytrue,divider))\n",
    "        #tf.print(\"xtrue\",xtrue)\n",
    "        \n",
    "        \n",
    "        ypred=tf.math.divide(y_pred,divider)\n",
    "        #tf.print(\"ypred\",ypred)\n",
    "        \n",
    "        xpred=tf.math.subtract(y_pred, tf.math.multiply(ypred,divider))\n",
    "        #tf.print(\"xpred\",xpred)\n",
    "        \n",
    "        xdiff=tf.math.abs(tf.math.subtract(xtrue,xpred))\n",
    "        #tf.print(\"xdiff\",xdiff)\n",
    "        \n",
    "        ydiff=tf.math.abs(tf.math.subtract(ytrue,ypred))\n",
    "        #tf.print(\"ydiff\",ydiff)\n",
    "        \n",
    "        \n",
    "        absDiff=tf.sqrt(tf.math.add(tf.square(xdiff),tf.square(ydiff)))\n",
    "        #tf.print(\"absDiff\",absDiff)\n",
    "        \n",
    "        mse = tf.reduce_mean(tf.square(absDiff))\n",
    "        #tf.print(\"mse\", mse)\n",
    "        \n",
    "        rmse = tf.math.sqrt(mse)\n",
    "        #tf.print(\"rmse\", rmse)\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662062b5",
   "metadata": {},
   "source": [
    "## Create model and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d6fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1369/Unknown - 2546s 2s/step - loss: 58.8587"
     ]
    }
   ],
   "source": [
    "# Set the learning rate scheduler\n",
    "#lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "#     lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "     lambda epoch: 1e-4)\n",
    "\n",
    "# Initialize the optimizer\n",
    "#optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "#optimizer=tf.keras.optimizers.Adam(learning_rate=0.000008)\n",
    "# Set the training parameters\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)\n",
    "model.compile(loss=CustomAccuracy(), optimizer=optimizer)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_set, epochs=10, callbacks=[lr_schedule])\n",
    "#history = model.fit(train_set, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get mae and loss from history log\n",
    "mae=history.history['mae']\n",
    "loss=history.history['loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs=range(len(loss)) \n",
    "\n",
    "# Plot mae and loss\n",
    "plot_series(\n",
    "    x=epochs, \n",
    "    y=(mae, loss), \n",
    "    title='MAE and Loss', \n",
    "    xlabel='Epochs',\n",
    "    legend=['MAE', 'Loss']\n",
    "    )\n",
    "\n",
    "# Only plot the last 80% of the epochs\n",
    "zoom_split = int(epochs[-1] * 0.2)\n",
    "epochs_zoom = epochs[zoom_split:]\n",
    "mae_zoom = mae[zoom_split:]\n",
    "loss_zoom = loss[zoom_split:]\n",
    "\n",
    "# Plot zoomed mae and loss\n",
    "plot_series(\n",
    "    x=epochs_zoom, \n",
    "    y=(mae_zoom, loss_zoom), \n",
    "    title='MAE and Loss', \n",
    "    xlabel='Epochs',\n",
    "    legend=['MAE', 'Loss']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b271fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    \"\"\"Uses an input model to generate predictions on data windows\n",
    "\n",
    "    Args:\n",
    "      model (TF Keras Model) - model that accepts data windows\n",
    "      series (array of float) - contains the values of the time series\n",
    "      window_size (int) - the number of time steps to include in the window\n",
    "      batch_size (int) - the batch size\n",
    "\n",
    "    Returns:\n",
    "      forecast (numpy array) - array containing predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a TF Dataset from the series values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "    # Window the data but only take those with the specified size\n",
    "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "\n",
    "    # Flatten the windows by putting its elements in a single batch\n",
    "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
    "    \n",
    "    # Create batches of windows\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    \n",
    "    # Get predictions on the entire dataset\n",
    "    forecast = model.predict(dataset)\n",
    "    \n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the original series\n",
    "forecast_series = series[split_time-window_size:-1]\n",
    "\n",
    "# Use helper function to generate predictions\n",
    "forecast = model_forecast(model, forecast_series, window_size, batch_size)\n",
    "\n",
    "# Drop single dimensional axes\n",
    "results = forecast.squeeze()\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_valid, (x_valid, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the MAE and MSE\n",
    "print(tf.keras.metrics.mean_squared_error(x_valid, results).numpy())\n",
    "print(tf.keras.metrics.mean_absolute_error(x_valid, results).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
